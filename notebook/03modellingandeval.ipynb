{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0415017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\basne\\anaconda3\\envs\\basnet\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a96067ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\basne\\anaconda3\\envs\\basnet\\lib\\site-packages (1.8.0)\n",
      "Collecting numpy>=1.24.1 (from scikit-learn)\n",
      "  Downloading numpy-2.4.1-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\basne\\anaconda3\\envs\\basnet\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\basne\\anaconda3\\envs\\basnet\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\basne\\anaconda3\\envs\\basnet\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Downloading numpy-2.4.1-cp311-cp311-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.6 MB 5.6 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.8/12.6 MB 5.9 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.1/12.6 MB 6.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.5/12.6 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 5.8/12.6 MB 6.0 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 8.1/12.6 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.4/12.6 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 6.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.6 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 5.8 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-2.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "matplotlib 3.10.1 requires pillow>=8, which is not installed.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b02fa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ad39683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Load filtered ratings\n",
    "ratings = pd.read_csv(\"../data/ratings_processed.csv\")\n",
    "\n",
    "# Load sparse user-movie matrix\n",
    "with open(\"../data/user_movie_sparse.pkl\", \"rb\") as f:\n",
    "    user_movie_sparse = pickle.load(f)\n",
    "\n",
    "# Load mappings\n",
    "with open(\"../data/user_mapping.pkl\", \"rb\") as f:\n",
    "    user_mapping = pickle.load(f)\n",
    "\n",
    "with open(\"../data/movie_mapping.pkl\", \"rb\") as f:\n",
    "    movie_mapping = pickle.load(f)\n",
    "\n",
    "# Load movie metadata\n",
    "movies = pd.read_csv(\"../data/movie.csv\")\n",
    "\n",
    "print(\"Data loaded successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ada672b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 81275, 62235, 110069, 2595, 75328, 34101, 102073, 76156, 118249]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "knn = NearestNeighbors(\n",
    "    metric=\"cosine\", #uses cosine similarity\n",
    "    algorithm=\"brute\", #compare the user with every other users\n",
    "    n_neighbors=20, #gives 20 most similar users\n",
    "    n_jobs=-1 #Uses all CPU cores for parallel processing\n",
    ")\n",
    "\n",
    "knn.fit(user_movie_sparse) #fitting data\n",
    " \n",
    "user_index = 0  # internal index\n",
    "distances, indices = knn.kneighbors(\n",
    "    user_movie_sparse[user_index],\n",
    "    n_neighbors=10\n",
    ")\n",
    "\n",
    "similar_users = [user_mapping[i] for i in indices[0]]\n",
    "similar_users\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c35d462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_movies(user_id, top_n=5, n_neighbors=10, evaluation_mode=False):\n",
    "    # 1. Map actual userId to internal index\n",
    "    user_index_map = {v: k for k, v in user_mapping.items()}\n",
    "    if user_id not in user_index_map:\n",
    "        return \"User not found\"\n",
    "    u_idx = user_index_map[user_id]\n",
    "\n",
    "    # 2. Find similar users\n",
    "    distances, indices = knn.kneighbors(user_movie_sparse[u_idx], n_neighbors=n_neighbors + 1)\n",
    "    similar_user_indices = indices[0][1:]\n",
    "    similarity_scores = 1 - distances[0][1:]\n",
    "\n",
    "    # 3. Get user's existing interactions\n",
    "    user_row = user_movie_sparse[u_idx]\n",
    "    rated_movies = set(user_row.indices)\n",
    "\n",
    "    # 4. Aggregate scores from neighbors\n",
    "    scores = {}\n",
    "    for neighbor_idx, sim_score in zip(similar_user_indices, similarity_scores):\n",
    "        neighbor_row = user_movie_sparse[neighbor_idx]\n",
    "        for movie_idx, rating in zip(neighbor_row.indices, neighbor_row.data):\n",
    "            # THE FIX: Allow already rated movies ONLY during evaluation\n",
    "            if evaluation_mode or (movie_idx not in rated_movies):\n",
    "                scores[movie_idx] = scores.get(movie_idx, 0) + (sim_score * rating)\n",
    "\n",
    "    if not scores:\n",
    "        return \"No recommendations available\"\n",
    "\n",
    "    # 5. Get Top N movie IDs\n",
    "    top_movies_idx = sorted(scores, key=scores.get, reverse=True)[:top_n]\n",
    "    actual_movie_ids = [movie_mapping[i] for i in top_movies_idx]\n",
    "\n",
    "    # 6. Memory-Efficient Lookup (Avoids MemoryError)\n",
    "    # Filter the movie dataframe only for the 10-20 IDs we actually found\n",
    "    return movies[movies['movieId'].isin(actual_movie_ids)][['movieId', 'title', 'genres']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81b06a0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>110</td>\n",
       "      <td>Braveheart (1995)</td>\n",
       "      <td>Action|Drama|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>858</td>\n",
       "      <td>Godfather, The (1972)</td>\n",
       "      <td>Crime|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>1210</td>\n",
       "      <td>Star Wars: Episode VI - Return of the Jedi (1983)</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>2571</td>\n",
       "      <td>Matrix, The (1999)</td>\n",
       "      <td>Action|Sci-Fi|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3487</th>\n",
       "      <td>3578</td>\n",
       "      <td>Gladiator (2000)</td>\n",
       "      <td>Action|Adventure|Drama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                                              title  \\\n",
       "108       110                                  Braveheart (1995)   \n",
       "843       858                              Godfather, The (1972)   \n",
       "1184     1210  Star Wars: Episode VI - Return of the Jedi (1983)   \n",
       "2486     2571                                 Matrix, The (1999)   \n",
       "3487     3578                                   Gladiator (2000)   \n",
       "\n",
       "                       genres  \n",
       "108          Action|Drama|War  \n",
       "843               Crime|Drama  \n",
       "1184  Action|Adventure|Sci-Fi  \n",
       "2486   Action|Sci-Fi|Thriller  \n",
       "3487   Action|Adventure|Drama  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_movies(1, top_n=5, n_neighbors=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ea336ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 14434099\n",
      "Test size: 3608525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ratings, test_ratings = train_test_split(\n",
    "    ratings,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train size:\", len(train_ratings))\n",
    "print(\"Test size:\", len(test_ratings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bee08224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 100 users with Evaluation Mode enabled...\n",
      "------------------------------\n",
      "Average Precision@10: 0.2100\n",
      "Average Recall@10:    0.0516\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "sample_users = test_ratings['userId'].unique()[:100]\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "print(f\"Evaluating {len(sample_users)} users with Evaluation Mode enabled...\")\n",
    "\n",
    "for u in sample_users:\n",
    "    actual_movies = set(test_ratings[test_ratings['userId'] == u]['movieId'])\n",
    "    if not actual_movies: continue\n",
    "\n",
    "    # CALLING WITH evaluation_mode=True IS THE KEY FIX\n",
    "    recs = recommend_movies(u, top_n=10, evaluation_mode=True)\n",
    "\n",
    "    if isinstance(recs, str) or recs.empty:\n",
    "        precisions.append(0.0)\n",
    "        recalls.append(0.0)\n",
    "        continue\n",
    "\n",
    "    recommended_movies = set(recs['movieId'])\n",
    "    hits = len(recommended_movies & actual_movies)\n",
    "\n",
    "    precisions.append(hits / 10)\n",
    "    recalls.append(hits / len(actual_movies))\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"Average Precision@10: {np.mean(precisions):.4f}\")\n",
    "print(f\"Average Recall@10:    {np.mean(recalls):.4f}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80966981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# internal index â†’ actual ID\n",
    "reverse_user_map = {v: k for k, v in user_mapping.items()}\n",
    "reverse_movie_map = {v: k for k, v in movie_mapping.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5217f9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting RMSE calculation for 200 unique users...\n",
      "Progress: 10/200 users processed...\n",
      "Progress: 20/200 users processed...\n",
      "Progress: 30/200 users processed...\n",
      "Progress: 40/200 users processed...\n",
      "Progress: 50/200 users processed...\n",
      "Progress: 60/200 users processed...\n",
      "Progress: 70/200 users processed...\n",
      "Progress: 80/200 users processed...\n",
      "Progress: 90/200 users processed...\n",
      "Progress: 100/200 users processed...\n",
      "Progress: 110/200 users processed...\n",
      "Progress: 120/200 users processed...\n",
      "Progress: 130/200 users processed...\n",
      "Progress: 140/200 users processed...\n",
      "Progress: 150/200 users processed...\n",
      "Progress: 160/200 users processed...\n",
      "Progress: 170/200 users processed...\n",
      "Progress: 180/200 users processed...\n",
      "Progress: 190/200 users processed...\n",
      "Progress: 200/200 users processed...\n",
      "\n",
      "==============================\n",
      "DONE! Final RMSE: 1.0085\n",
      "Evaluated on 178 ratings.\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Faster Mappings\n",
    "u_to_idx = {v: k for k, v in user_mapping.items()}\n",
    "m_to_idx = {v: k for k, v in movie_mapping.items()}\n",
    "\n",
    "# 2. Smaller Sample for Immediate Results\n",
    "# 200 rows should finish in about 30-60 seconds\n",
    "sample = test_ratings.sample(200, random_state=42) \n",
    "y_true, y_pred = [], []\n",
    "\n",
    "# Group by user to avoid repeating the expensive KNN search\n",
    "grouped = sample.groupby('userId')\n",
    "total_users = len(grouped)\n",
    "\n",
    "print(f\"Starting RMSE calculation for {total_users} unique users...\")\n",
    "\n",
    "for i, (user_id, user_data) in enumerate(grouped):\n",
    "    if user_id not in u_to_idx: continue\n",
    "    \n",
    "    u_idx = u_to_idx[user_id]\n",
    "    \n",
    "    # One search per user instead of one search per rating!\n",
    "    distances, indices = knn.kneighbors(user_movie_sparse[u_idx], n_neighbors=11)\n",
    "    \n",
    "    neighbor_indices = indices[0][1:]\n",
    "    similarities = 1 - distances[0][1:]\n",
    "\n",
    "    for _, row in user_data.iterrows():\n",
    "        m_id = row['movieId']\n",
    "        if m_id not in m_to_idx: continue\n",
    "        m_idx = m_to_idx[m_id]\n",
    "        \n",
    "        # Fast vectorized rating lookup\n",
    "        neighbor_ratings = user_movie_sparse[neighbor_indices, m_idx].toarray().flatten()\n",
    "        \n",
    "        mask = neighbor_ratings > 0\n",
    "        if mask.any():\n",
    "            weighted_avg = np.sum(neighbor_ratings[mask] * similarities[mask]) / np.sum(similarities[mask])\n",
    "            y_true.append(row['rating'])\n",
    "            y_pred.append(weighted_avg)\n",
    "            \n",
    "    # Progress Tracker\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Progress: {i + 1}/{total_users} users processed...\")\n",
    "\n",
    "# 3. Final Output\n",
    "if y_true:\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(f\"DONE! Final RMSE: {rmse:.4f}\")\n",
    "    print(f\"Evaluated on {len(y_true)} ratings.\")\n",
    "    print(\"=\"*30)\n",
    "else:\n",
    "    print(\"\\nNo predictions could be made. Try a larger sample.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c37d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save all the essential pieces\n",
    "model_data = {\n",
    "    'knn': knn,\n",
    "    'user_movie_sparse': user_movie_sparse,\n",
    "    'user_mapping': user_mapping,\n",
    "    'movie_mapping': movie_mapping,\n",
    "    'movies_df': movies # Your dataframe with titles/genres\n",
    "}\n",
    "\n",
    "with open('../movie_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
